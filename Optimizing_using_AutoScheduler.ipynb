{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tvm\n",
        "from tvm import te, auto_scheduler"
      ],
      "metadata": {
        "id": "Qbfiziv359VH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@auto_scheduler.register_workload\n",
        "def matmul_add(N, L, M, dtype):\n",
        "    A = te.placeholder((N, L), name=\"A\", dtype=dtype)\n",
        "    B = te.placeholder((L, M), name=\"B\", dtype=dtype)\n",
        "    C = te.placeholder((N, M), name=\"C\", dtype=dtype)\n",
        "\n",
        "    k = te.reduce_axis((0, L), name=\"k\")\n",
        "    matmul = te.compute(\n",
        "        (N, M),\n",
        "        lambda i, j: te.sum(A[i, k] * B[k, j], axis=k),\n",
        "        name=\"matmul\",\n",
        "        attrs={\"layout_free_placeholders\": [B]},  # enable automatic layout transform for tensor B\n",
        "    )\n",
        "    out = te.compute((N, M), lambda i, j: matmul[i, j] + C[i, j], name=\"out\")\n",
        "\n",
        "    return [A, B, C, out]"
      ],
      "metadata": {
        "id": "kkCbXSt559Xb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target = tvm.target.Target(\"llvm\")\n",
        "N = L = M = 1024\n",
        "task = tvm.auto_scheduler.SearchTask(func=matmul_add, args=(N, L, M, \"float32\"), target=target)\n",
        "\n",
        "# Inspect the computational graph\n",
        "print(\"Computational DAG:\")\n",
        "print(task.compute_dag)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xWp01OP59Yr",
        "outputId": "fd936010-9fd8-4300-bf71-5fd27e528461"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computational DAG:\n",
            "A = PLACEHOLDER [1024, 1024]\n",
            "B = PLACEHOLDER [1024, 1024]\n",
            "matmul(i, j) += (A[i, k]*B[k, j])\n",
            "C = PLACEHOLDER [1024, 1024]\n",
            "out(i, j) = (matmul[i, j] + C[i, j])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "log_file = \"matmul.json\"\n",
        "tune_option = auto_scheduler.TuningOptions(\n",
        "    num_measure_trials=10,\n",
        "    measure_callbacks=[auto_scheduler.RecordToFile(log_file)],\n",
        "    verbose=2,\n",
        ")"
      ],
      "metadata": {
        "id": "ETEeWcIO59Z2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run auto-tuning (search)\n",
        "task.tune(tune_option)\n",
        "# Apply the best schedule\n",
        "sch, args = task.apply_best(log_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-bcMOK859cF",
        "outputId": "b9561d21-7e94-4f23-ee99-8f026156666c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "*E\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Lowered TIR:\")\n",
        "print(tvm.lower(sch, args, simple_mode=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBjc1FIO59di",
        "outputId": "08a34976-2b0c-497e-aae8-d0fe22b0540c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lowered TIR:\n",
            "@main = primfn(A_1: handle, B_1: handle, C_1: handle, out_1: handle) -> ()\n",
            "  attr = {\"from_legacy_te_schedule\": True, \"global_symbol\": \"main\", \"tir.noalias\": True}\n",
            "  buffers = {A: Buffer(A_2: Pointer(float32), float32, [1024, 1024], []),\n",
            "             B: Buffer(B_2: Pointer(float32), float32, [1024, 1024], []),\n",
            "             C: Buffer(C_2: Pointer(float32), float32, [1024, 1024], []),\n",
            "             out: Buffer(out_2: Pointer(float32), float32, [1024, 1024], [])}\n",
            "  buffer_map = {A_1: A, B_1: B, C_1: C, out_1: out} {\n",
            "  allocate(auto_scheduler_layout_transform: Pointer(global float32), float32, [1048576]), storage_scope = global;\n",
            "  allocate(matmul: Pointer(global float32), float32, [1048576]), storage_scope = global {\n",
            "    for (ax0.ax1.fused.ax2.fused: int32, 0, 1024) \"parallel\" {\n",
            "      for (ax3: int32, 0, 32) {\n",
            "        for (ax4: int32, 0, 8) {\n",
            "          for (ax5: int32, 0, 4) {\n",
            "            auto_scheduler_layout_transform_1: Buffer(auto_scheduler_layout_transform, float32, [1048576], [])[((((ax0.ax1.fused.ax2.fused*1024) + (ax3*32)) + (ax4*4)) + ax5)] = B_3: Buffer(B_2, float32, [1048576], [])[(((((floormod(ax0.ax1.fused.ax2.fused, 128)*8192) + (ax4*1024)) + (floordiv(ax0.ax1.fused.ax2.fused, 128)*128)) + (ax3*4)) + ax5)]\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    for (i.outer.outer.outer: int32, 0, 256) \"parallel\" {\n",
            "      for (j.outer.outer.inner: int32, 0, 8) {\n",
            "        for (i.outer.inner.init: int32, 0, 2) {\n",
            "          let cse_var_1: int32 = (((i.outer.outer.outer*4096) + (i.outer.inner.init*2048)) + (j.outer.outer.inner*128))\n",
            "           {\n",
            "            matmul_1: Buffer(matmul, float32, [1048576], [])[ramp(cse_var_1, 1, 4)] = broadcast(0f32, 4)\n",
            "            matmul_1[ramp((cse_var_1 + 1024), 1, 4)] = broadcast(0f32, 4)\n",
            "            matmul_1[ramp((cse_var_1 + 4), 1, 4)] = broadcast(0f32, 4)\n",
            "            matmul_1[ramp((cse_var_1 + 1028), 1, 4)] = broadcast(0f32, 4)\n",
            "            matmul_1[ramp((cse_var_1 + 8), 1, 4)] = broadcast(0f32, 4)\n",
            "            matmul_1[ramp((cse_var_1 + 1032), 1, 4)] = broadcast(0f32, 4)\n",
            "            matmul_1[ramp((cse_var_1 + 12), 1, 4)] = broadcast(0f32, 4)\n",
            "            matmul_1[ramp((cse_var_1 + 1036), 1, 4)] = broadcast(0f32, 4)\n",
            "            matmul_1[ramp((cse_var_1 + 16), 1, 4)] = broadcast(0f32, 4)\n",
            "            matmul_1[ramp((cse_var_1 + 1040), 1, 4)] = broadcast(0f32, 4)\n",
            "            matmul_1[ramp((cse_var_1 + 20), 1, 4)] = broadcast(0f32, 4)\n",
            "            matmul_1[ramp((cse_var_1 + 1044), 1, 4)] = broadcast(0f32, 4)\n",
            "            matmul_1[ramp((cse_var_1 + 24), 1, 4)] = broadcast(0f32, 4)\n",
            "            matmul_1[ramp((cse_var_1 + 1048), 1, 4)] = broadcast(0f32, 4)\n",
            "            matmul_1[ramp((cse_var_1 + 28), 1, 4)] = broadcast(0f32, 4)\n",
            "            matmul_1[ramp((cse_var_1 + 1052), 1, 4)] = broadcast(0f32, 4)\n",
            "            matmul_1[ramp((cse_var_1 + 32), 1, 4)] = broadcast(0f32, 4)\n",
            "            matmul_1[ramp((cse_var_1 + 1056), 1, 4)] = broadcast(0f32, 4)\n",
            "            matmul_1[ramp((cse_var_1 + 36), 1, 4)] = broadcast(0f32, 4)\n",
            "            matmul_1[ramp((cse_var_1 + 1060), 1, 4)] = broadcast(0f32, 4)\n",
            "            matmul_1[ramp((cse_var_1 + 40), 1, 4)] = broadcast(0f32, 4)\n",
            "            matmul_1[ramp((cse_var_1 + 1064), 1, 4)] = broadcast(0f32, 4)\n",
            "            matmul_1[ramp((cse_var_1 + 44), 1, 4)] = broadcast(0f32, 4)\n",
            "            matmul_1[ramp((cse_var_1 + 1068), 1, 4)] = broadcast(0f32, 4)\n",
            "            matmul_1[ramp((cse_var_1 + 48), 1, 4)] = broadcast(0f32, 4)\n",
            "            matmul_1[ramp((cse_var_1 + 1072), 1, 4)] = broadcast(0f32, 4)\n",
            "            matmul_1[ramp((cse_var_1 + 52), 1, 4)] = broadcast(0f32, 4)\n",
            "            matmul_1[ramp((cse_var_1 + 1076), 1, 4)] = broadcast(0f32, 4)\n",
            "            matmul_1[ramp((cse_var_1 + 56), 1, 4)] = broadcast(0f32, 4)\n",
            "            matmul_1[ramp((cse_var_1 + 1080), 1, 4)] = broadcast(0f32, 4)\n",
            "            matmul_1[ramp((cse_var_1 + 60), 1, 4)] = broadcast(0f32, 4)\n",
            "            matmul_1[ramp((cse_var_1 + 1084), 1, 4)] = broadcast(0f32, 4)\n",
            "            matmul_1[ramp((cse_var_1 + 64), 1, 4)] = broadcast(0f32, 4)\n",
            "            matmul_1[ramp((cse_var_1 + 1088), 1, 4)] = broadcast(0f32, 4)\n",
            "            matmul_1[ramp((cse_var_1 + 68), 1, 4)] = broadcast(0f32, 4)\n",
            "            matmul_1[ramp((cse_var_1 + 1092), 1, 4)] = broadcast(0f32, 4)\n",
            "            matmul_1[ramp((cse_var_1 + 72), 1, 4)] = broadcast(0f32, 4)\n",
            "            matmul_1[ramp((cse_var_1 + 1096), 1, 4)] = broadcast(0f32, 4)\n",
            "            matmul_1[ramp((cse_var_1 + 76), 1, 4)] = broadcast(0f32, 4)\n",
            "            matmul_1[ramp((cse_var_1 + 1100), 1, 4)] = broadcast(0f32, 4)\n",
            "            matmul_1[ramp((cse_var_1 + 80), 1, 4)] = broadcast(0f32, 4)\n",
            "            matmul_1[ramp((cse_var_1 + 1104), 1, 4)] = broadcast(0f32, 4)\n",
            "            matmul_1[ramp((cse_var_1 + 84), 1, 4)] = broadcast(0f32, 4)\n",
            "            matmul_1[ramp((cse_var_1 + 1108), 1, 4)] = broadcast(0f32, 4)\n",
            "            matmul_1[ramp((cse_var_1 + 88), 1, 4)] = broadcast(0f32, 4)\n",
            "            matmul_1[ramp((cse_var_1 + 1112), 1, 4)] = broadcast(0f32, 4)\n",
            "            matmul_1[ramp((cse_var_1 + 92), 1, 4)] = broadcast(0f32, 4)\n",
            "            matmul_1[ramp((cse_var_1 + 1116), 1, 4)] = broadcast(0f32, 4)\n",
            "            matmul_1[ramp((cse_var_1 + 96), 1, 4)] = broadcast(0f32, 4)\n",
            "            matmul_1[ramp((cse_var_1 + 1120), 1, 4)] = broadcast(0f32, 4)\n",
            "            matmul_1[ramp((cse_var_1 + 100), 1, 4)] = broadcast(0f32, 4)\n",
            "            matmul_1[ramp((cse_var_1 + 1124), 1, 4)] = broadcast(0f32, 4)\n",
            "            matmul_1[ramp((cse_var_1 + 104), 1, 4)] = broadcast(0f32, 4)\n",
            "            matmul_1[ramp((cse_var_1 + 1128), 1, 4)] = broadcast(0f32, 4)\n",
            "            matmul_1[ramp((cse_var_1 + 108), 1, 4)] = broadcast(0f32, 4)\n",
            "            matmul_1[ramp((cse_var_1 + 1132), 1, 4)] = broadcast(0f32, 4)\n",
            "            matmul_1[ramp((cse_var_1 + 112), 1, 4)] = broadcast(0f32, 4)\n",
            "            matmul_1[ramp((cse_var_1 + 1136), 1, 4)] = broadcast(0f32, 4)\n",
            "            matmul_1[ramp((cse_var_1 + 116), 1, 4)] = broadcast(0f32, 4)\n",
            "            matmul_1[ramp((cse_var_1 + 1140), 1, 4)] = broadcast(0f32, 4)\n",
            "            matmul_1[ramp((cse_var_1 + 120), 1, 4)] = broadcast(0f32, 4)\n",
            "            matmul_1[ramp((cse_var_1 + 1144), 1, 4)] = broadcast(0f32, 4)\n",
            "            matmul_1[ramp((cse_var_1 + 124), 1, 4)] = broadcast(0f32, 4)\n",
            "            matmul_1[ramp((cse_var_1 + 1148), 1, 4)] = broadcast(0f32, 4)\n",
            "          }\n",
            "        }\n",
            "        for (k.outer: int32, 0, 128) {\n",
            "          for (i.outer.inner: int32, 0, 2) {\n",
            "            for (j.outer.inner: int32, 0, 32) {\n",
            "              let cse_var_13: int32 = ((i.outer.outer.outer*4096) + (i.outer.inner*2048))\n",
            "              let cse_var_12: int32 = (((j.outer.outer.inner*131072) + (k.outer*1024)) + (j.outer.inner*32))\n",
            "              let cse_var_11: int32 = (cse_var_13 + (k.outer*8))\n",
            "              let cse_var_10: int32 = (cse_var_12 + 8)\n",
            "              let cse_var_9: int32 = (cse_var_12 + 4)\n",
            "              let cse_var_8: int32 = (cse_var_12 + 28)\n",
            "              let cse_var_7: int32 = (cse_var_12 + 24)\n",
            "              let cse_var_6: int32 = (cse_var_12 + 20)\n",
            "              let cse_var_5: int32 = (cse_var_12 + 16)\n",
            "              let cse_var_4: int32 = (cse_var_12 + 12)\n",
            "              let cse_var_3: int32 = ((cse_var_13 + (j.outer.outer.inner*128)) + (j.outer.inner*4))\n",
            "              let cse_var_2: int32 = (cse_var_3 + 1024)\n",
            "               {\n",
            "                matmul_1[ramp(cse_var_3, 1, 4)] = (matmul_1[ramp(cse_var_3, 1, 4)] + (broadcast(A_3: Buffer(A_2, float32, [1048576], [])[cse_var_11], 4)*auto_scheduler_layout_transform_1[ramp(cse_var_12, 1, 4)]))\n",
            "                matmul_1[ramp(cse_var_2, 1, 4)] = (matmul_1[ramp(cse_var_2, 1, 4)] + (broadcast(A_3[(cse_var_11 + 1024)], 4)*auto_scheduler_layout_transform_1[ramp(cse_var_12, 1, 4)]))\n",
            "                matmul_1[ramp(cse_var_3, 1, 4)] = (matmul_1[ramp(cse_var_3, 1, 4)] + (broadcast(A_3[(cse_var_11 + 1)], 4)*auto_scheduler_layout_transform_1[ramp(cse_var_9, 1, 4)]))\n",
            "                matmul_1[ramp(cse_var_2, 1, 4)] = (matmul_1[ramp(cse_var_2, 1, 4)] + (broadcast(A_3[(cse_var_11 + 1025)], 4)*auto_scheduler_layout_transform_1[ramp(cse_var_9, 1, 4)]))\n",
            "                matmul_1[ramp(cse_var_3, 1, 4)] = (matmul_1[ramp(cse_var_3, 1, 4)] + (broadcast(A_3[(cse_var_11 + 2)], 4)*auto_scheduler_layout_transform_1[ramp(cse_var_10, 1, 4)]))\n",
            "                matmul_1[ramp(cse_var_2, 1, 4)] = (matmul_1[ramp(cse_var_2, 1, 4)] + (broadcast(A_3[(cse_var_11 + 1026)], 4)*auto_scheduler_layout_transform_1[ramp(cse_var_10, 1, 4)]))\n",
            "                matmul_1[ramp(cse_var_3, 1, 4)] = (matmul_1[ramp(cse_var_3, 1, 4)] + (broadcast(A_3[(cse_var_11 + 3)], 4)*auto_scheduler_layout_transform_1[ramp(cse_var_4, 1, 4)]))\n",
            "                matmul_1[ramp(cse_var_2, 1, 4)] = (matmul_1[ramp(cse_var_2, 1, 4)] + (broadcast(A_3[(cse_var_11 + 1027)], 4)*auto_scheduler_layout_transform_1[ramp(cse_var_4, 1, 4)]))\n",
            "                matmul_1[ramp(cse_var_3, 1, 4)] = (matmul_1[ramp(cse_var_3, 1, 4)] + (broadcast(A_3[(cse_var_11 + 4)], 4)*auto_scheduler_layout_transform_1[ramp(cse_var_5, 1, 4)]))\n",
            "                matmul_1[ramp(cse_var_2, 1, 4)] = (matmul_1[ramp(cse_var_2, 1, 4)] + (broadcast(A_3[(cse_var_11 + 1028)], 4)*auto_scheduler_layout_transform_1[ramp(cse_var_5, 1, 4)]))\n",
            "                matmul_1[ramp(cse_var_3, 1, 4)] = (matmul_1[ramp(cse_var_3, 1, 4)] + (broadcast(A_3[(cse_var_11 + 5)], 4)*auto_scheduler_layout_transform_1[ramp(cse_var_6, 1, 4)]))\n",
            "                matmul_1[ramp(cse_var_2, 1, 4)] = (matmul_1[ramp(cse_var_2, 1, 4)] + (broadcast(A_3[(cse_var_11 + 1029)], 4)*auto_scheduler_layout_transform_1[ramp(cse_var_6, 1, 4)]))\n",
            "                matmul_1[ramp(cse_var_3, 1, 4)] = (matmul_1[ramp(cse_var_3, 1, 4)] + (broadcast(A_3[(cse_var_11 + 6)], 4)*auto_scheduler_layout_transform_1[ramp(cse_var_7, 1, 4)]))\n",
            "                matmul_1[ramp(cse_var_2, 1, 4)] = (matmul_1[ramp(cse_var_2, 1, 4)] + (broadcast(A_3[(cse_var_11 + 1030)], 4)*auto_scheduler_layout_transform_1[ramp(cse_var_7, 1, 4)]))\n",
            "                matmul_1[ramp(cse_var_3, 1, 4)] = (matmul_1[ramp(cse_var_3, 1, 4)] + (broadcast(A_3[(cse_var_11 + 7)], 4)*auto_scheduler_layout_transform_1[ramp(cse_var_8, 1, 4)]))\n",
            "                matmul_1[ramp(cse_var_2, 1, 4)] = (matmul_1[ramp(cse_var_2, 1, 4)] + (broadcast(A_3[(cse_var_11 + 1031)], 4)*auto_scheduler_layout_transform_1[ramp(cse_var_8, 1, 4)]))\n",
            "              }\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    for (i: int32, 0, 1024) \"parallel\" {\n",
            "      for (j: int32, 0, 1024) {\n",
            "        let cse_var_14: int32 = ((i*1024) + j)\n",
            "        out_3: Buffer(out_2, float32, [1048576], [])[cse_var_14] = (matmul_1[cse_var_14] + C_3: Buffer(C_2, float32, [1048576], [])[cse_var_14])\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "func = tvm.build(sch, args, target)\n",
        "a_np = np.random.uniform(size=(N, L)).astype(np.float32)\n",
        "b_np = np.random.uniform(size=(L, M)).astype(np.float32)\n",
        "c_np = np.random.uniform(size=(N, M)).astype(np.float32)\n",
        "out_np = a_np.dot(b_np) + c_np\n",
        "\n",
        "dev = tvm.cpu()\n",
        "a_tvm = tvm.nd.array(a_np, device=dev)\n",
        "b_tvm = tvm.nd.array(b_np, device=dev)\n",
        "c_tvm = tvm.nd.array(c_np, device=dev)\n",
        "out_tvm = tvm.nd.empty(out_np.shape, device=dev)\n",
        "func(a_tvm, b_tvm, c_tvm, out_tvm)\n",
        "\n",
        "# Check results\n",
        "np.testing.assert_allclose(out_np, out_tvm.numpy(), rtol=1e-3)\n",
        "\n",
        "# Evaluate execution time.\n",
        "evaluator = func.time_evaluator(func.entry_name, dev, min_repeat_ms=500)\n",
        "print(\n",
        "    \"Execution time of this operator: %.3f ms\"\n",
        "    % (np.median(evaluator(a_tvm, b_tvm, c_tvm, out_tvm).results) * 1000)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4s9xKiY59fU",
        "outputId": "f03edd3c-0e36-4bdd-844d-733e77cf6667"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution time of this operator: 170.208 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Equivalent python schedule:\")\n",
        "print(task.print_best(log_file))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7N6rJv459gU",
        "outputId": "dc3b6d26-cb53-44fb-b018-8ad4a7ed3363"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Equivalent python schedule:\n",
            "matmul_i, matmul_j, matmul_k = tuple(matmul.op.axis) + tuple(matmul.op.reduce_axis)\n",
            "out_i, out_j = tuple(out.op.axis) + tuple(out.op.reduce_axis)\n",
            "matmul_i_o_i, matmul_i_i = s[matmul].split(matmul_i, factor=2)\n",
            "matmul_i_o_o_i, matmul_i_o_i = s[matmul].split(matmul_i_o_i, factor=2)\n",
            "matmul_i_o_o_o, matmul_i_o_o_i = s[matmul].split(matmul_i_o_o_i, factor=1)\n",
            "matmul_j_o_i, matmul_j_i = s[matmul].split(matmul_j, factor=4)\n",
            "matmul_j_o_o_i, matmul_j_o_i = s[matmul].split(matmul_j_o_i, factor=32)\n",
            "matmul_j_o_o_o, matmul_j_o_o_i = s[matmul].split(matmul_j_o_o_i, factor=8)\n",
            "matmul_k_o, matmul_k_i = s[matmul].split(matmul_k, factor=8)\n",
            "s[matmul].reorder(matmul_i_o_o_o, matmul_j_o_o_o, matmul_i_o_o_i, matmul_j_o_o_i, matmul_k_o, matmul_i_o_i, matmul_j_o_i, matmul_k_i, matmul_i_i, matmul_j_i)\n",
            "s[matmul].parallel(matmul_i_o_o_o)\n",
            "s[out].parallel(out_i)\n",
            "s[matmul].pragma(matmul_i_o_o_o, \"auto_unroll_max_step\", 64)\n",
            "s[matmul].pragma(matmul_i_o_o_o, \"unroll_explicit\", True)\n",
            "s[matmul].vectorize(matmul_j_i)\n",
            "\n"
          ]
        }
      ]
    }
  ]
}
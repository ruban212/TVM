{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NBXclun8zYd",
        "outputId": "5f5548ac-8826-435c-ca51-8469a09427d5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from onnx) (1.26.4)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n",
            "Downloading onnx-1.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/15.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/15.9 MB\u001b[0m \u001b[31m179.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m13.0/15.9 MB\u001b[0m \u001b[31m201.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m201.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m201.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m88.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx\n",
            "Successfully installed onnx-1.16.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install apache-tvm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCaHTIW-8zUR",
        "outputId": "626b19f1-3e17-4e5f-cc4d-f9e42a95e195"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting apache-tvm\n",
            "  Downloading apache_tvm-0.11.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from apache-tvm) (24.2.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from apache-tvm) (2.2.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from apache-tvm) (4.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from apache-tvm) (1.26.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from apache-tvm) (5.9.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from apache-tvm) (1.13.1)\n",
            "Collecting synr==0.6.0 (from apache-tvm)\n",
            "  Downloading synr-0.6.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.10/dist-packages (from apache-tvm) (6.3.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from apache-tvm) (4.12.2)\n",
            "Downloading apache_tvm-0.11.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading synr-0.6.0-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: synr, apache-tvm\n",
            "Successfully installed apache-tvm-0.11.1 synr-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import onnx\n",
        "from tvm.contrib.download import download_testdata\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import tvm.relay as relay\n",
        "import tvm\n",
        "from tvm.contrib import graph_executor"
      ],
      "metadata": {
        "id": "QfVIqe7K8zC4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_url = (\n",
        "    \"https://github.com/onnx/models/raw/bd206494e8b6a27b25e5cf7199dbcdbfe9d05d1c/\"\n",
        "    \"vision/classification/resnet/model/\"\n",
        "    \"resnet50-v2-7.onnx\"\n",
        ")\n",
        "\n",
        "model_path = download_testdata(model_url, \"resnet50-v2-7.onnx\", module=\"onnx\")\n",
        "onnx_model = onnx.load(model_path)\n",
        "\n",
        "# Seed numpy's RNG to get consistent results\n",
        "np.random.seed(0)"
      ],
      "metadata": {
        "id": "TbTLz6XJ8y-D"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_url = \"https://s3.amazonaws.com/model-server/inputs/kitten.jpg\"\n",
        "img_path = download_testdata(img_url, \"imagenet_cat.png\", module=\"data\")\n",
        "\n",
        "# Resize it to 224x224\n",
        "resized_image = Image.open(img_path).resize((224, 224))\n",
        "img_data = np.asarray(resized_image).astype(\"float32\")\n",
        "\n",
        "# Our input image is in HWC layout while ONNX expects CHW input, so convert the array\n",
        "img_data = np.transpose(img_data, (2, 0, 1))\n",
        "\n",
        "# Normalize according to the ImageNet input specification\n",
        "imagenet_mean = np.array([0.485, 0.456, 0.406]).reshape((3, 1, 1))\n",
        "imagenet_stddev = np.array([0.229, 0.224, 0.225]).reshape((3, 1, 1))\n",
        "norm_img_data = (img_data / 255 - imagenet_mean) / imagenet_stddev\n",
        "\n",
        "# Add the batch dimension, as we are expecting 4-dimensional input: NCHW.\n",
        "img_data = np.expand_dims(norm_img_data, axis=0)"
      ],
      "metadata": {
        "id": "FmbN4V298y8R"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target = \"llvm\""
      ],
      "metadata": {
        "id": "hbPlyFgH8y6k"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The input name may vary across model types. You can use a tool\n",
        "# like Netron to check input names\n",
        "input_name = \"data\"\n",
        "shape_dict = {input_name: img_data.shape}\n",
        "\n",
        "mod, params = relay.frontend.from_onnx(onnx_model, shape_dict)\n",
        "\n",
        "with tvm.transform.PassContext(opt_level=3):\n",
        "    lib = relay.build(mod, target=target, params=params)\n",
        "\n",
        "dev = tvm.device(str(target), 0)\n",
        "module = graph_executor.GraphModule(lib[\"default\"](dev))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAPNM1zO8y4y",
        "outputId": "29166ee4-896f-483c-db05-3137fbc03b5a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autotvm:One or more operators have not been tuned. Please tune your model for better performance. Use DEBUG logging level to see more details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dtype = \"float32\"\n",
        "module.set_input(input_name, img_data)\n",
        "module.run()\n",
        "output_shape = (1, 1000)\n",
        "tvm_output = module.get_output(0, tvm.nd.empty(output_shape)).numpy()"
      ],
      "metadata": {
        "id": "bRbsXArC8y3A"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import timeit\n",
        "\n",
        "timing_number = 10\n",
        "timing_repeat = 10\n",
        "unoptimized = (\n",
        "    np.array(timeit.Timer(lambda: module.run()).repeat(repeat=timing_repeat, number=timing_number))\n",
        "    * 1000\n",
        "    / timing_number\n",
        ")\n",
        "unoptimized = {\n",
        "    \"mean\": np.mean(unoptimized),\n",
        "    \"median\": np.median(unoptimized),\n",
        "    \"std\": np.std(unoptimized),\n",
        "}\n",
        "\n",
        "print(unoptimized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UG4EJIHk8y1P",
        "outputId": "f8acd289-4eea-4a5c-b70d-01f8c24a3161"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'mean': 570.2164998800026, 'median': 595.123998400004, 'std': 53.95169570036884}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.special import softmax\n",
        "\n",
        "# Download a list of labels\n",
        "labels_url = \"https://s3.amazonaws.com/onnx-model-zoo/synset.txt\"\n",
        "labels_path = download_testdata(labels_url, \"synset.txt\", module=\"data\")\n",
        "\n",
        "with open(labels_path, \"r\") as f:\n",
        "    labels = [l.rstrip() for l in f]\n",
        "\n",
        "# Open the output and read the output tensor\n",
        "scores = softmax(tvm_output)\n",
        "scores = np.squeeze(scores)\n",
        "ranks = np.argsort(scores)[::-1]\n",
        "for rank in ranks[0:5]:\n",
        "    print(\"class='%s' with probability=%f\" % (labels[rank], scores[rank]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iH-OYI9g8yzd",
        "outputId": "1d3c0247-b73f-424f-9a8f-4733ff977680"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class='n02123045 tabby, tabby cat' with probability=0.621103\n",
            "class='n02123159 tiger cat' with probability=0.356379\n",
            "class='n02124075 Egyptian cat' with probability=0.019712\n",
            "class='n02129604 tiger, Panthera tigris' with probability=0.001215\n",
            "class='n04040759 radiator' with probability=0.000262\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tvm.auto_scheduler as auto_scheduler\n",
        "from tvm.autotvm.tuner import XGBTuner\n",
        "from tvm import autotvm"
      ],
      "metadata": {
        "id": "xOgVnvIQ8yxu"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "number = 10\n",
        "repeat = 1\n",
        "min_repeat_ms = 0  # since we're tuning on a CPU, can be set to 0\n",
        "timeout = 10  # in seconds\n",
        "\n",
        "# create a TVM runner\n",
        "runner = autotvm.LocalRunner(\n",
        "    number=number,\n",
        "    repeat=repeat,\n",
        "    timeout=timeout,\n",
        "    min_repeat_ms=min_repeat_ms,\n",
        "    enable_cpu_cache_flush=True,\n",
        ")"
      ],
      "metadata": {
        "id": "74NxzFzb8ywC"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuning_option = {\n",
        "    \"tuner\": \"xgb\",\n",
        "    \"trials\": 20,\n",
        "    \"early_stopping\": 100,\n",
        "    \"measure_option\": autotvm.measure_option(\n",
        "        builder=autotvm.LocalBuilder(build_func=\"default\"), runner=runner\n",
        "    ),\n",
        "    \"tuning_records\": \"resnet-50-v2-autotuning.json\",\n",
        "}"
      ],
      "metadata": {
        "id": "kQwHUhyu8ysT"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# begin by extracting the tasks from the onnx model\n",
        "tasks = autotvm.task.extract_from_program(mod[\"main\"], target=target, params=params)\n",
        "\n",
        "# Tune the extracted tasks sequentially.\n",
        "for i, task in enumerate(tasks):\n",
        "    prefix = \"[Task %2d/%2d] \" % (i + 1, len(tasks))\n",
        "\n",
        "    # choose tuner\n",
        "    tuner = \"xgb\"\n",
        "\n",
        "    # create tuner\n",
        "    if tuner == \"xgb\":\n",
        "        tuner_obj = XGBTuner(task, loss_type=\"reg\")\n",
        "    elif tuner == \"xgb_knob\":\n",
        "        tuner_obj = XGBTuner(task, loss_type=\"reg\", feature_type=\"knob\")\n",
        "    elif tuner == \"xgb_itervar\":\n",
        "        tuner_obj = XGBTuner(task, loss_type=\"reg\", feature_type=\"itervar\")\n",
        "    elif tuner == \"xgb_curve\":\n",
        "        tuner_obj = XGBTuner(task, loss_type=\"reg\", feature_type=\"curve\")\n",
        "    elif tuner == \"xgb_rank\":\n",
        "        tuner_obj = XGBTuner(task, loss_type=\"rank\")\n",
        "    elif tuner == \"xgb_rank_knob\":\n",
        "        tuner_obj = XGBTuner(task, loss_type=\"rank\", feature_type=\"knob\")\n",
        "    elif tuner == \"xgb_rank_itervar\":\n",
        "        tuner_obj = XGBTuner(task, loss_type=\"rank\", feature_type=\"itervar\")\n",
        "    elif tuner == \"xgb_rank_curve\":\n",
        "        tuner_obj = XGBTuner(task, loss_type=\"rank\", feature_type=\"curve\")\n",
        "    elif tuner == \"xgb_rank_binary\":\n",
        "        tuner_obj = XGBTuner(task, loss_type=\"rank-binary\")\n",
        "    elif tuner == \"xgb_rank_binary_knob\":\n",
        "        tuner_obj = XGBTuner(task, loss_type=\"rank-binary\", feature_type=\"knob\")\n",
        "    elif tuner == \"xgb_rank_binary_itervar\":\n",
        "        tuner_obj = XGBTuner(task, loss_type=\"rank-binary\", feature_type=\"itervar\")\n",
        "    elif tuner == \"xgb_rank_binary_curve\":\n",
        "        tuner_obj = XGBTuner(task, loss_type=\"rank-binary\", feature_type=\"curve\")\n",
        "    elif tuner == \"ga\":\n",
        "        tuner_obj = GATuner(task, pop_size=50)\n",
        "    elif tuner == \"random\":\n",
        "        tuner_obj = RandomTuner(task)\n",
        "    elif tuner == \"gridsearch\":\n",
        "        tuner_obj = GridSearchTuner(task)\n",
        "    else:\n",
        "        raise ValueError(\"Invalid tuner: \" + tuner)\n",
        "\n",
        "    tuner_obj.tune(\n",
        "        n_trial=min(tuning_option[\"trials\"], len(task.config_space)),\n",
        "        early_stopping=tuning_option[\"early_stopping\"],\n",
        "        measure_option=tuning_option[\"measure_option\"],\n",
        "        callbacks=[\n",
        "            autotvm.callback.progress_bar(tuning_option[\"trials\"], prefix=prefix),\n",
        "            autotvm.callback.log_to_file(tuning_option[\"tuning_records\"]),\n",
        "        ],\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "JQWfhNOB-_WI",
        "outputId": "60ec53d3-8ff5-4402-94ee-cc6c5a37c33e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Task  2/25]  Current/Best:    7.93/  22.06 GFLOPS | Progress: (20/20) | 16.91 s Done.\n",
            "[Task  3/25]  Current/Best:    7.60/  21.89 GFLOPS | Progress: (20/20) | 18.96 s Done.\n",
            "[Task  4/25]  Current/Best:    3.63/  20.84 GFLOPS | Progress: (20/20) | 22.86 s Done.\n",
            "[Task  5/25]  Current/Best:    5.62/  18.16 GFLOPS | Progress: (20/20) | 18.22 s Done.\n",
            "[Task  6/25]  Current/Best:    6.18/  20.42 GFLOPS | Progress: (20/20) | 24.65 s Done.\n",
            "[Task  7/25]  Current/Best:   15.31/  22.75 GFLOPS | Progress: (20/20) | 21.62 s Done.\n",
            "[Task  9/25]  Current/Best:    0.00/   0.00 GFLOPS | Progress: (0/20) | 0.00 s Done.\n",
            "[Task  9/25]  Current/Best:   21.17/  21.73 GFLOPS | Progress: (20/20) | 34.38 s Done.\n",
            "[Task 10/25]  Current/Best:    9.52/  21.30 GFLOPS | Progress: (20/20) | 20.13 s Done.\n",
            "[Task 11/25]  Current/Best:   13.32/  23.72 GFLOPS | Progress: (20/20) | 19.74 s Done.\n",
            "[Task 12/25]  Current/Best:   18.88/  18.88 GFLOPS | Progress: (20/20) | 34.23 s Done.\n",
            "[Task 13/25]  Current/Best:    5.26/  23.07 GFLOPS | Progress: (20/20) | 28.14 s Done.\n",
            "[Task 15/25]  Current/Best:   10.25/  19.57 GFLOPS | Progress: (20/20) | 27.50 s Done.\n",
            "[Task 16/25]  Current/Best:   15.30/  21.40 GFLOPS | Progress: (20/20) | 20.08 s Done.\n",
            "[Task 17/25]  Current/Best:   17.22/  23.20 GFLOPS | Progress: (20/20) | 22.49 s Done.\n",
            "[Task 18/25]  Current/Best:    3.63/  21.60 GFLOPS | Progress: (20/20) | 22.75 s Done.\n",
            "[Task 19/25]  Current/Best:   19.45/  19.45 GFLOPS | Progress: (20/20) | 30.68 s Done.\n",
            "[Task 21/25]  Current/Best:    4.40/   7.61 GFLOPS | Progress: (2/20) | 3.33 s Done.\n",
            " Done.\n",
            "[Task 21/25]  Current/Best:   13.19/  21.85 GFLOPS | Progress: (20/20) | 29.78 s Done.\n",
            "[Task 22/25]  Current/Best:   11.23/  22.23 GFLOPS | Progress: (20/20) | 18.75 s Done.\n",
            "[Task 23/25]  Current/Best:   17.06/  22.42 GFLOPS | Progress: (20/20) | 25.50 s Done.\n",
            "[Task 25/25]  Current/Best:    2.91/   8.75 GFLOPS | Progress: (20/20) | 32.44 s"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with autotvm.apply_history_best(tuning_option[\"tuning_records\"]):\n",
        "    with tvm.transform.PassContext(opt_level=3, config={}):\n",
        "        lib = relay.build(mod, target=target, params=params)\n",
        "\n",
        "dev = tvm.device(str(target), 0)\n",
        "module = graph_executor.GraphModule(lib[\"default\"](dev))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eXOzJ3H-_Yp",
        "outputId": "8e037d3b-1732-4c75-8e13-c01996d17398"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Done.\n",
            " Done.\n",
            " Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dtype = \"float32\"\n",
        "module.set_input(input_name, img_data)\n",
        "module.run()\n",
        "output_shape = (1, 1000)\n",
        "tvm_output = module.get_output(0, tvm.nd.empty(output_shape)).numpy()\n",
        "\n",
        "scores = softmax(tvm_output)\n",
        "scores = np.squeeze(scores)\n",
        "ranks = np.argsort(scores)[::-1]\n",
        "for rank in ranks[0:5]:\n",
        "    print(\"class='%s' with probability=%f\" % (labels[rank], scores[rank]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOr2QCXW-_bZ",
        "outputId": "9c12313d-8dca-4a49-99fe-38e5fbd9c1ce"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class='n02123045 tabby, tabby cat' with probability=0.621104\n",
            "class='n02123159 tiger cat' with probability=0.356378\n",
            "class='n02124075 Egyptian cat' with probability=0.019712\n",
            "class='n02129604 tiger, Panthera tigris' with probability=0.001215\n",
            "class='n04040759 radiator' with probability=0.000262\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import timeit\n",
        "\n",
        "timing_number = 10\n",
        "timing_repeat = 10\n",
        "optimized = (\n",
        "    np.array(timeit.Timer(lambda: module.run()).repeat(repeat=timing_repeat, number=timing_number))\n",
        "    * 1000\n",
        "    / timing_number\n",
        ")\n",
        "optimized = {\"mean\": np.mean(optimized), \"median\": np.median(optimized), \"std\": np.std(optimized)}\n",
        "\n",
        "\n",
        "print(\"optimized: %s\" % (optimized))\n",
        "print(\"unoptimized: %s\" % (unoptimized))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9CmTuUi-_fm",
        "outputId": "159261b7-f785-4446-b90f-334284df7296"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "optimized: {'mean': 465.24422492999975, 'median': 462.8887104499995, 'std': 71.43288802898373}\n",
            "unoptimized: {'mean': 570.2164998800026, 'median': 595.123998400004, 'std': 53.95169570036884}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xTTJeWFS-_is"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}